{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "sc = pyspark.SparkContext()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pyspark.sql.functions as F\n",
    "from pyspark.sql.functions import when\n",
    "from kneed import KneeLocator\n",
    "from yellowbrick.cluster import KElbowVisualizer\n",
    "from pyspark.ml.feature import Normalizer, MinMaxScaler, VectorAssembler, StandardScaler\n",
    "from pyspark.sql import Row, Column\n",
    "from pyspark.sql.types import FloatType, DoubleType\n",
    "import plotly.graph_objects as go\n",
    "from pyspark.mllib.linalg import DenseVector\n",
    "\n",
    "from pyspark.ml.classification import MultilayerPerceptronClassifier\n",
    "\n",
    "from pyspark.mllib.evaluation import MulticlassMetrics\n",
    "from pyspark.mllib.tree import LabeledPoint\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, roc_curve, auc\n",
    "import numpy as np\n",
    "import itertools\n",
    "\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.sql.functions import udf, mean, stddev\n",
    "\n",
    "from pyspark.ml.feature import StringIndexer, VectorIndexer, StandardScaler, VectorAssembler\n",
    "\n",
    "\n",
    "from pyspark.ml.tuning import ParamGridBuilder, CrossValidator\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator, MulticlassClassificationEvaluator, ClusteringEvaluator\n",
    "from pyspark.mllib.evaluation import MulticlassMetrics, BinaryClassificationMetrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import StructType, StructField\n",
    "spark = SparkSession.builder \\\n",
    "    .config(\"spark.some.config.option\", \"some-value\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters_path = \"hdfs://kddrtserver13.isti.cnr.it:9000/user/hpsa15/kmeans_cluster_\"\n",
    "optimals_path = \"hdfs://kddrtserver13.isti.cnr.it:9000/user/hpsa15/multilayerperceptron_optimals.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Numeri dei clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_v = [0, 1, 2, 3, 4, 5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Lettura dei clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters_df = {}\n",
    "for i in prediction_v:\n",
    "    clusters_df[i] = spark.read.options(inferSchema = True, header = True)\\\n",
    "                .csv(clusters_path+str(i)+\".csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_numeric = [\"age\", \"duration\", \"campaign\", \"pdays\", \"previous\",\n",
    "                  \"emp_var_rate\", \"cons_price_idx\", \"cons_conf_idx\", \"euribor3m\",\n",
    "                  \"nr_employed\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxIters = [100, 150, 200, 250]\n",
    "blockSize = [32, 64, 128]\n",
    "layers = [[10,6, 4, 2], [10, 8, 6, 4, 2], [10, 8, 2]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuned_param = {}\n",
    "s = 0\n",
    "for i in maxIters:\n",
    "    for j in blockSize:\n",
    "        for k in layers:\n",
    "            tuned_param[\"sharp_\"+str(s)] = {\"maxIters\": i, \"blockSize\": j, \"layers\": k}\n",
    "            s = s + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sharp_0': {'maxIters': 100, 'blockSize': 32, 'layers': [10, 6, 4, 2]},\n",
       " 'sharp_1': {'maxIters': 100, 'blockSize': 32, 'layers': [10, 8, 6, 4, 2]},\n",
       " 'sharp_2': {'maxIters': 100, 'blockSize': 32, 'layers': [10, 8, 2]},\n",
       " 'sharp_3': {'maxIters': 100, 'blockSize': 64, 'layers': [10, 6, 4, 2]},\n",
       " 'sharp_4': {'maxIters': 100, 'blockSize': 64, 'layers': [10, 8, 6, 4, 2]},\n",
       " 'sharp_5': {'maxIters': 100, 'blockSize': 64, 'layers': [10, 8, 2]},\n",
       " 'sharp_6': {'maxIters': 100, 'blockSize': 128, 'layers': [10, 6, 4, 2]},\n",
       " 'sharp_7': {'maxIters': 100, 'blockSize': 128, 'layers': [10, 8, 6, 4, 2]},\n",
       " 'sharp_8': {'maxIters': 100, 'blockSize': 128, 'layers': [10, 8, 2]},\n",
       " 'sharp_9': {'maxIters': 150, 'blockSize': 32, 'layers': [10, 6, 4, 2]},\n",
       " 'sharp_10': {'maxIters': 150, 'blockSize': 32, 'layers': [10, 8, 6, 4, 2]},\n",
       " 'sharp_11': {'maxIters': 150, 'blockSize': 32, 'layers': [10, 8, 2]},\n",
       " 'sharp_12': {'maxIters': 150, 'blockSize': 64, 'layers': [10, 6, 4, 2]},\n",
       " 'sharp_13': {'maxIters': 150, 'blockSize': 64, 'layers': [10, 8, 6, 4, 2]},\n",
       " 'sharp_14': {'maxIters': 150, 'blockSize': 64, 'layers': [10, 8, 2]},\n",
       " 'sharp_15': {'maxIters': 150, 'blockSize': 128, 'layers': [10, 6, 4, 2]},\n",
       " 'sharp_16': {'maxIters': 150, 'blockSize': 128, 'layers': [10, 8, 6, 4, 2]},\n",
       " 'sharp_17': {'maxIters': 150, 'blockSize': 128, 'layers': [10, 8, 2]},\n",
       " 'sharp_18': {'maxIters': 200, 'blockSize': 32, 'layers': [10, 6, 4, 2]},\n",
       " 'sharp_19': {'maxIters': 200, 'blockSize': 32, 'layers': [10, 8, 6, 4, 2]},\n",
       " 'sharp_20': {'maxIters': 200, 'blockSize': 32, 'layers': [10, 8, 2]},\n",
       " 'sharp_21': {'maxIters': 200, 'blockSize': 64, 'layers': [10, 6, 4, 2]},\n",
       " 'sharp_22': {'maxIters': 200, 'blockSize': 64, 'layers': [10, 8, 6, 4, 2]},\n",
       " 'sharp_23': {'maxIters': 200, 'blockSize': 64, 'layers': [10, 8, 2]},\n",
       " 'sharp_24': {'maxIters': 200, 'blockSize': 128, 'layers': [10, 6, 4, 2]},\n",
       " 'sharp_25': {'maxIters': 200, 'blockSize': 128, 'layers': [10, 8, 6, 4, 2]},\n",
       " 'sharp_26': {'maxIters': 200, 'blockSize': 128, 'layers': [10, 8, 2]},\n",
       " 'sharp_27': {'maxIters': 250, 'blockSize': 32, 'layers': [10, 6, 4, 2]},\n",
       " 'sharp_28': {'maxIters': 250, 'blockSize': 32, 'layers': [10, 8, 6, 4, 2]},\n",
       " 'sharp_29': {'maxIters': 250, 'blockSize': 32, 'layers': [10, 8, 2]},\n",
       " 'sharp_30': {'maxIters': 250, 'blockSize': 64, 'layers': [10, 6, 4, 2]},\n",
       " 'sharp_31': {'maxIters': 250, 'blockSize': 64, 'layers': [10, 8, 6, 4, 2]},\n",
       " 'sharp_32': {'maxIters': 250, 'blockSize': 64, 'layers': [10, 8, 2]},\n",
       " 'sharp_33': {'maxIters': 250, 'blockSize': 128, 'layers': [10, 6, 4, 2]},\n",
       " 'sharp_34': {'maxIters': 250, 'blockSize': 128, 'layers': [10, 8, 6, 4, 2]},\n",
       " 'sharp_35': {'maxIters': 250, 'blockSize': 128, 'layers': [10, 8, 2]}}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tuned_param"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grid(df, prediction_v, tuned_param):\n",
    "    optimals = {}\n",
    "    evaluatorMulti = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\")\n",
    "    evaluator = BinaryClassificationEvaluator(labelCol=\"label\", rawPredictionCol=\"prediction\", metricName='areaUnderROC')\n",
    "    for i in prediction_v:\n",
    "        assembler = VectorAssembler().setInputCols(features_numeric).setOutputCol(\"features\")\n",
    "        tmp_df = assembler.transform(df[i])\n",
    "        tmp_df = tmp_df.withColumnRenamed(\"y\",\"label\")\n",
    "        # Training e test\n",
    "        train1, test = tmp_df.randomSplit([0.7, 0.3], seed = 2)\n",
    "        # Training e validation\n",
    "        train, val = train1.randomSplit([0.7, 0.3], seed = 2)\n",
    "        f1 = 0\n",
    "        s_tmp = \"\"\n",
    "        print(\"------------ Grid per cluster \" + str(i) + \" ------------\")\n",
    "        for j in tuned_param:            \n",
    "            mlp = MultilayerPerceptronClassifier(maxIter = tuned_param[j][\"maxIters\"], layers = tuned_param[j][\"layers\"], blockSize = tuned_param[j][\"blockSize\"], seed=1002)\n",
    "            print(\"Effettuato \" + str(j))\n",
    "            model = mlp.fit(train)\n",
    "\n",
    "            # Make predicitons\n",
    "            predictionAndTarget = model.transform(val).select(\"label\", \"prediction\")\n",
    "            \n",
    "            f1_new = evaluatorMulti.evaluate(predictionAndTarget, {evaluatorMulti.metricName: \"f1\"})\n",
    "            # Massimizziamo F1\n",
    "            if(f1_new > f1):\n",
    "                s_tmp = j\n",
    "        print(\" > Parametri migliori \")\n",
    "        print(s_tmp)\n",
    "        # Metriche Reali\n",
    "        optimals[i] = {\"maxIter\": tuned_param[s_tmp][\"maxIters\"], \"layers\" : tuned_param[s_tmp][\"layers\"], \"blockSize\": tuned_param[s_tmp][\"blockSize\"]}\n",
    "        print(optimals[i])\n",
    "        mlp = MultilayerPerceptronClassifier(maxIter = tuned_param[s_tmp][\"maxIters\"], layers = tuned_param[s_tmp][\"layers\"], blockSize = tuned_param[s_tmp][\"blockSize\"], seed=1002)\n",
    "        model = mlp.fit(train1)\n",
    "        predictionAndTarget = model.transform(test).select(\"label\", \"prediction\")\n",
    "        print(\" > Valutazioni\")\n",
    "        acc = evaluatorMulti.evaluate(predictionAndTarget, {evaluatorMulti.metricName: \"accuracy\"})\n",
    "        f1 = evaluatorMulti.evaluate(predictionAndTarget, {evaluatorMulti.metricName: \"f1\"})\n",
    "        weightedPrecision = evaluatorMulti.evaluate(predictionAndTarget, {evaluatorMulti.metricName: \"weightedPrecision\"})\n",
    "        weightedRecall = evaluatorMulti.evaluate(predictionAndTarget, {evaluatorMulti.metricName: \"weightedRecall\"})\n",
    "        auc = evaluator.evaluate(predictionAndTarget)\n",
    "        print(\" - Accuracy = \" + str(acc))\n",
    "        print(\" - F1 score = \" + str(f1))\n",
    "        print(\" - Weighted Precision = \" + str(weightedPrecision))\n",
    "        print(\" - Weighted Recall = \" + str(weightedRecall))\n",
    "        print(\" - AUC = \" + str(auc))\n",
    "    return optimals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------ Grid per cluster 0 ------------\n",
      "Effettuato sharp_0\n",
      "Effettuato sharp_1\n",
      "Effettuato sharp_2\n",
      "Effettuato sharp_3\n",
      "Effettuato sharp_4\n",
      "Effettuato sharp_5\n",
      "Effettuato sharp_6\n",
      "Effettuato sharp_7\n",
      "Effettuato sharp_8\n",
      "Effettuato sharp_9\n",
      "Effettuato sharp_10\n",
      "Effettuato sharp_11\n",
      "Effettuato sharp_12\n",
      "Effettuato sharp_13\n",
      "Effettuato sharp_14\n",
      "Effettuato sharp_15\n",
      "Effettuato sharp_16\n",
      "Effettuato sharp_17\n",
      "Effettuato sharp_18\n",
      "Effettuato sharp_19\n",
      "Effettuato sharp_20\n",
      "Effettuato sharp_21\n",
      "Effettuato sharp_22\n",
      "Effettuato sharp_23\n",
      "Effettuato sharp_24\n",
      "Effettuato sharp_25\n",
      "Effettuato sharp_26\n",
      "Effettuato sharp_27\n",
      "Effettuato sharp_28\n",
      "Effettuato sharp_29\n",
      "Effettuato sharp_30\n",
      "Effettuato sharp_31\n",
      "Effettuato sharp_32\n",
      "Effettuato sharp_33\n",
      "Effettuato sharp_34\n",
      "Effettuato sharp_35\n",
      " > Parametri migliori \n",
      "sharp_35\n",
      "{'maxIter': 250, 'layers': [10, 8, 2], 'blockSize': 128}\n",
      " > Valutazioni\n",
      " - Accuracy = 0.764065335753176\n",
      " - F1 score = 0.6618755274734303\n",
      " - Weighted Precision = 0.5837958372996137\n",
      " - Weighted Recall = 0.764065335753176\n",
      " - AUC = 0.5\n",
      "------------ Grid per cluster 1 ------------\n",
      "Effettuato sharp_0\n",
      "Effettuato sharp_1\n",
      "Effettuato sharp_2\n",
      "Effettuato sharp_3\n",
      "Effettuato sharp_4\n",
      "Effettuato sharp_5\n",
      "Effettuato sharp_6\n",
      "Effettuato sharp_7\n",
      "Effettuato sharp_8\n",
      "Effettuato sharp_9\n",
      "Effettuato sharp_10\n",
      "Effettuato sharp_11\n",
      "Effettuato sharp_12\n",
      "Effettuato sharp_13\n",
      "Effettuato sharp_14\n",
      "Effettuato sharp_15\n",
      "Effettuato sharp_16\n",
      "Effettuato sharp_17\n",
      "Effettuato sharp_18\n",
      "Effettuato sharp_19\n",
      "Effettuato sharp_20\n",
      "Effettuato sharp_21\n",
      "Effettuato sharp_22\n",
      "Effettuato sharp_23\n",
      "Effettuato sharp_24\n",
      "Effettuato sharp_25\n",
      "Effettuato sharp_26\n",
      "Effettuato sharp_27\n",
      "Effettuato sharp_28\n",
      "Effettuato sharp_29\n",
      "Effettuato sharp_30\n",
      "Effettuato sharp_31\n",
      "Effettuato sharp_32\n",
      "Effettuato sharp_33\n",
      "Effettuato sharp_34\n",
      "Effettuato sharp_35\n",
      " > Parametri migliori \n",
      "sharp_35\n",
      "{'maxIter': 250, 'layers': [10, 8, 2], 'blockSize': 128}\n",
      " > Valutazioni\n",
      " - Accuracy = 0.9191857815585599\n",
      " - F1 score = 0.8804801589695815\n",
      " - Weighted Precision = 0.8449025010194207\n",
      " - Weighted Recall = 0.9191857815585599\n",
      " - AUC = 0.5\n",
      "------------ Grid per cluster 2 ------------\n",
      "Effettuato sharp_0\n",
      "Effettuato sharp_1\n",
      "Effettuato sharp_2\n",
      "Effettuato sharp_3\n",
      "Effettuato sharp_4\n",
      "Effettuato sharp_5\n",
      "Effettuato sharp_6\n",
      "Effettuato sharp_7\n",
      "Effettuato sharp_8\n",
      "Effettuato sharp_9\n",
      "Effettuato sharp_10\n",
      "Effettuato sharp_11\n",
      "Effettuato sharp_12\n",
      "Effettuato sharp_13\n",
      "Effettuato sharp_14\n",
      "Effettuato sharp_15\n",
      "Effettuato sharp_16\n",
      "Effettuato sharp_17\n",
      "Effettuato sharp_18\n",
      "Effettuato sharp_19\n",
      "Effettuato sharp_20\n",
      "Effettuato sharp_21\n",
      "Effettuato sharp_22\n",
      "Effettuato sharp_23\n",
      "Effettuato sharp_24\n",
      "Effettuato sharp_25\n",
      "Effettuato sharp_26\n",
      "Effettuato sharp_27\n",
      "Effettuato sharp_28\n",
      "Effettuato sharp_29\n",
      "Effettuato sharp_30\n",
      "Effettuato sharp_31\n",
      "Effettuato sharp_32\n",
      "Effettuato sharp_33\n",
      "Effettuato sharp_34\n",
      "Effettuato sharp_35\n",
      " > Parametri migliori \n",
      "sharp_35\n",
      "{'maxIter': 250, 'layers': [10, 8, 2], 'blockSize': 128}\n",
      " > Valutazioni\n",
      " - Accuracy = 0.5963636363636363\n",
      " - F1 score = 0.4455746531372955\n",
      " - Weighted Precision = 0.3556495867768595\n",
      " - Weighted Recall = 0.5963636363636363\n",
      " - AUC = 0.5\n",
      "------------ Grid per cluster 3 ------------\n",
      "Effettuato sharp_0\n",
      "Effettuato sharp_1\n",
      "Effettuato sharp_2\n",
      "Effettuato sharp_3\n",
      "Effettuato sharp_4\n",
      "Effettuato sharp_5\n",
      "Effettuato sharp_6\n",
      "Effettuato sharp_7\n",
      "Effettuato sharp_8\n",
      "Effettuato sharp_9\n",
      "Effettuato sharp_10\n",
      "Effettuato sharp_11\n",
      "Effettuato sharp_12\n",
      "Effettuato sharp_13\n",
      "Effettuato sharp_14\n",
      "Effettuato sharp_15\n",
      "Effettuato sharp_16\n",
      "Effettuato sharp_17\n",
      "Effettuato sharp_18\n",
      "Effettuato sharp_19\n",
      "Effettuato sharp_20\n",
      "Effettuato sharp_21\n",
      "Effettuato sharp_22\n",
      "Effettuato sharp_23\n",
      "Effettuato sharp_24\n",
      "Effettuato sharp_25\n",
      "Effettuato sharp_26\n",
      "Effettuato sharp_27\n",
      "Effettuato sharp_28\n",
      "Effettuato sharp_29\n",
      "Effettuato sharp_30\n",
      "Effettuato sharp_31\n",
      "Effettuato sharp_32\n",
      "Effettuato sharp_33\n",
      "Effettuato sharp_34\n",
      "Effettuato sharp_35\n",
      " > Parametri migliori \n",
      "sharp_35\n",
      "{'maxIter': 250, 'layers': [10, 8, 2], 'blockSize': 128}\n",
      " > Valutazioni\n",
      " - Accuracy = 0.5588235294117647\n",
      " - F1 score = 0.40066592674805773\n",
      " - Weighted Precision = 0.31228373702422146\n",
      " - Weighted Recall = 0.5588235294117647\n",
      " - AUC = 0.5\n",
      "------------ Grid per cluster 4 ------------\n",
      "Effettuato sharp_0\n",
      "Effettuato sharp_1\n",
      "Effettuato sharp_2\n",
      "Effettuato sharp_3\n",
      "Effettuato sharp_4\n",
      "Effettuato sharp_5\n",
      "Effettuato sharp_6\n",
      "Effettuato sharp_7\n",
      "Effettuato sharp_8\n",
      "Effettuato sharp_9\n",
      "Effettuato sharp_10\n",
      "Effettuato sharp_11\n",
      "Effettuato sharp_12\n",
      "Effettuato sharp_13\n",
      "Effettuato sharp_14\n",
      "Effettuato sharp_15\n",
      "Effettuato sharp_16\n",
      "Effettuato sharp_17\n",
      "Effettuato sharp_18\n",
      "Effettuato sharp_19\n",
      "Effettuato sharp_20\n",
      "Effettuato sharp_21\n",
      "Effettuato sharp_22\n",
      "Effettuato sharp_23\n",
      "Effettuato sharp_24\n",
      "Effettuato sharp_25\n",
      "Effettuato sharp_26\n",
      "Effettuato sharp_27\n",
      "Effettuato sharp_28\n",
      "Effettuato sharp_29\n",
      "Effettuato sharp_30\n",
      "Effettuato sharp_31\n",
      "Effettuato sharp_32\n",
      "Effettuato sharp_33\n",
      "Effettuato sharp_34\n",
      "Effettuato sharp_35\n",
      " > Parametri migliori \n",
      "sharp_35\n",
      "{'maxIter': 250, 'layers': [10, 8, 2], 'blockSize': 128}\n",
      " > Valutazioni\n",
      " - Accuracy = 0.916807738814994\n",
      " - F1 score = 0.8770169411677119\n",
      " - Weighted Precision = 0.8405364299510621\n",
      " - Weighted Recall = 0.916807738814994\n",
      " - AUC = 0.5\n",
      "------------ Grid per cluster 5 ------------\n",
      "Effettuato sharp_0\n",
      "Effettuato sharp_1\n",
      "Effettuato sharp_2\n",
      "Effettuato sharp_3\n",
      "Effettuato sharp_4\n",
      "Effettuato sharp_5\n",
      "Effettuato sharp_6\n",
      "Effettuato sharp_7\n",
      "Effettuato sharp_8\n",
      "Effettuato sharp_9\n",
      "Effettuato sharp_10\n",
      "Effettuato sharp_11\n",
      "Effettuato sharp_12\n",
      "Effettuato sharp_13\n",
      "Effettuato sharp_14\n",
      "Effettuato sharp_15\n",
      "Effettuato sharp_16\n",
      "Effettuato sharp_17\n",
      "Effettuato sharp_18\n",
      "Effettuato sharp_19\n",
      "Effettuato sharp_20\n",
      "Effettuato sharp_21\n",
      "Effettuato sharp_22\n",
      "Effettuato sharp_23\n",
      "Effettuato sharp_24\n",
      "Effettuato sharp_25\n",
      "Effettuato sharp_26\n",
      "Effettuato sharp_27\n",
      "Effettuato sharp_28\n",
      "Effettuato sharp_29\n",
      "Effettuato sharp_30\n",
      "Effettuato sharp_31\n",
      "Effettuato sharp_32\n",
      "Effettuato sharp_33\n",
      "Effettuato sharp_34\n",
      "Effettuato sharp_35\n",
      " > Parametri migliori \n",
      "sharp_35\n",
      "{'maxIter': 250, 'layers': [10, 8, 2], 'blockSize': 128}\n",
      " > Valutazioni\n",
      " - Accuracy = 0.5384615384615384\n",
      " - F1 score = 0.37692307692307697\n",
      " - Weighted Precision = 0.28994082840236685\n",
      " - Weighted Recall = 0.5384615384615384\n",
      " - AUC = 0.5\n"
     ]
    }
   ],
   "source": [
    "optimals = grid(clusters_df, prediction_v, tuned_param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: {'maxIter': 250, 'layers': [10, 8, 2], 'blockSize': 128},\n",
       " 1: {'maxIter': 250, 'layers': [10, 8, 2], 'blockSize': 128},\n",
       " 2: {'maxIter': 250, 'layers': [10, 8, 2], 'blockSize': 128},\n",
       " 3: {'maxIter': 250, 'layers': [10, 8, 2], 'blockSize': 128},\n",
       " 4: {'maxIter': 250, 'layers': [10, 8, 2], 'blockSize': 128},\n",
       " 5: {'maxIter': 250, 'layers': [10, 8, 2], 'blockSize': 128}}"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimals[0][\"layers\"][1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Salvataggio valori ottimi (backup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "# Eseguire solo se è stata eseguita la crossvalidation\n",
    "def opt_towrite(optimals):\n",
    "    ll = []\n",
    "    for i in range(0, 6):\n",
    "        x ={}\n",
    "        x[\"clusters\"] = i\n",
    "        x[\"maxIter\"] = optimals[i][\"maxIter\"]\n",
    "        ss = str(optimals[i][\"layers\"][0])\n",
    "        for j in range(1, len(optimals[i][\"layers\"])):\n",
    "            ss = ss+\"_\"+str(optimals[i][\"layers\"][j])\n",
    "        x[\"layers\"] = ss\n",
    "        x[\"blockSize\"] = optimals[i][\"blockSize\"]\n",
    "        ll.append(x)\n",
    "    df_optimals = spark.createDataFrame(ll)\n",
    "    df_optimals.write.format(\"csv\").save(\"hdfs://kddrtserver13.isti.cnr.it:9000/user/hpsa15/multilayerperceptron_optimals.csv\", header = True)\n",
    "\n",
    "opt_towrite(optimals)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+--------+------+-------+\n",
      "|blockSize|clusters|layers|maxIter|\n",
      "+---------+--------+------+-------+\n",
      "|      128|       1|10_8_2|    250|\n",
      "|      128|       2|10_8_2|    250|\n",
      "|      128|       4|10_8_2|    250|\n",
      "|      128|       5|10_8_2|    250|\n",
      "|      128|       0|10_8_2|    250|\n",
      "|      128|       3|10_8_2|    250|\n",
      "+---------+--------+------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "optimals_df = spark.read.options(inferSchema = True, header = True)\\\n",
    "                .csv(optimals_path)    \n",
    "optimals_df.show()\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
